Common Signature Method README
1. 	Data is collected according to the following criteria: datasets must only contain samples directly from human patients, samples must be extracted from a tissue directly affected by the phenotype of interest, the datasets must contain a minimum number of three controls and three patients, accepted datasets could be both microarray and RNA-Seq.
2. 	Data is submitted to quality control to assure data quality and remove outliers.
3. 	Case-control gene expression analysis is conducted using LIMMA (microarray) or DESeq2 (RNA-Seq) on each individual dataset. Genes are selected based on consensus direction of expression. Overlap with condition-generic signatures and unaffected tissue signatures are removed.
4. 	Genes are used to seed a protein-protein interaction network generated from Irefindex 14 data. Included proteins must share at least one interaction with a DEG’s protein.
5. 	The PPI network members are used to build a coexpression matrix in each dataset. These datasets are analysed for appropriate distribution. Those included are compared to identify conserved edges that share the same correlation direction above a certain threshold.
6. 	The largest connected component is selected, and coexpression edge overlap with condition-generic signatures and unaffected tissue signatures is removed.
7. 	The members of the network undergo prioritisation to identify likely candidates for in vitro/vivo validation, calling upon genetic, topological, regulatory, consensus and phenotype-specific sources of information.
8. 	The selected targets’ effect on the common phenotype is assessed in vitro/vivo.


Step One - finding the right data
The expression data you select for the experiment is largely uncomplicated to find. I tended to look on Gene Expression Omnibus or ArrayExpress. The selection process is as set out in Step 1. The platforms you choose to include are up to you and your preferences/skill sets. Just try and keep the preprocessing pipelines as consistent within microarray/RNA-seq as possible.

Step Two - quality control and preprocessing
Quality control of samples can be done in a number of ways, there are no strict rules. I decided to use PCA, boxplots and clustering to identify outliers, but you could use anything else as long as it’s well supported. Microarray data can be processed as .CEL files, which can be downloaded straight from GEO/ArrayExpress. RNA-seq data will need to be processed to generate a count matrix. We do this using bcbio, but there may be other preferable methods. Refer to Pseudocode_CommonSignature.R sections “Quality Control” and “Pre-processing” for code.

Step Three - differential expression analysis
Differential expression analysis can be conducted using a number of different packages. We chose LIMMA and DESeq2 as these are well-supported methodologies and suited to the type of data they are designed for. Other packages could be used if preferred. Examples of the scripts used to analyse the data can be found here - Limma Example, DESeq2 Example. The LIMMA script takes .CEL files as input, the DESeq2 script will take a count matrix. Once these are run on each dataset, the genes with a positive fold change and a negative fold change are separated, and a consensus identified across datasets. An example of the script used to conduct this can be found here -. It is here that the filtering datasets are included. Choosing filtering datasets can be difficult, as the perfect data may not be available. The aim of this step is to filter out confounding signal which may be included in your signature. I set out two main types of dataset - condition-generic signatures and unaffected tissue - which I believed eradicated much of the confounders, however this process could potentially be improved. Refer to Pseudocode_CommonSignature.R section “Common DEGS” for code.

Step Four - protein interaction network
The previous set produces a list of gene names. These gene names will need to be converted into Uniprot IDs so that the protein interaction database (whichever you choose, I used IrefIndex 14.0) can be queried. To do this I used the package BioMart, however the accuracy of this was not 100% - some genes weren’t paired with the appropriate protein symbol, and some had multiple options. I would usually need to go through by hand to work out which gene’s hadn’t been given a protein symbol and then find that on the UniProt website. Perhaps the newer version of IrefIndex (15.0) is better populated, or perhaps another protein interaction database could be used. I didn’t have the time or the expertise to investigate my options fully. Once the UniProt symbols were identified, I extracted all the rows containing at least one of the DEG proteins. This formed the protein interaction network. Refer to Pseudocode_CommonSignature.R section “Protein Interaction Network” for code.

Step Five - coexpression network
To rebuild this network with coexpression edges, I took the nodes (proteins) and ran a correlation analysis for every possible pair. This was repeated in each of the input datasets. Because the coexpression networks were generally pretty big (2000-3000 nodes often) these calculations would take quite a long time - possibly about an hour per dataset. Subsequently I ran these experiments in parallel on the High Performance Computer which sped up the process of analysis overall. Note these files are pretty big and R Studio will struggle with them. Once read into R, the filters were added to reduce the number of edges. It’s at this point that you need to choose a correlation value threshold. This is not an exact science, it might take a little trial and error. I found it to be pretty consistently somewhere between 0.45 and 0.55, but sometimes it may need to go a little higher. I didn’t use the correlation P Values, as I wasn’t convinced they were particularly reliable. The correlation value was used to ensure consistent direction of correlation. Results were visualised in Cytoscape. Refer to Pseudocode_CommonSignature.R sections “Coexpression Network”, “Common Correlations” and “Filter Correlations” for code.
Step Six - Prioritisation
At this stage prioritisation could be done in a number of ways, it’s up to the user. The methodology I used was one that I developed using a mix of information sources. This is covered in my thesis in Chapter 2, section 2.3.4 “Target Prioritisation”.
